{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zainstaluj paczki potrzebne do uruchomienia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install Tkinter\n",
    "%pip install streamlit\n",
    "%pip install mlxtend\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Po zainstalowaniu paczek można uruchomić program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "import subprocess\n",
    "\n",
    "class Application(tk.Frame):\n",
    "    def __init__(self, master=None):\n",
    "        super().__init__(master)\n",
    "        self.master = master\n",
    "        self.master.title(\"Generator skryptów Streamlit\")\n",
    "        self.pack()\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.tabControl = ttk.Notebook(self)\n",
    "        self.tabControl.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        self.tab1 = ttk.Frame(self.tabControl)\n",
    "        self.tabControl.add(self.tab1, text=\"Reguły asocjacyjne\")\n",
    "        self.create_tab1_widgets()\n",
    "\n",
    "        self.tab2 = ttk.Frame(self.tabControl)\n",
    "        self.tabControl.add(self.tab2, text=\"Klasyfikator-KNN\")\n",
    "        self.create_tab2_widgets()\n",
    "\n",
    "        self.tab4 = ttk.Frame(self.tabControl)\n",
    "        self.tabControl.add(self.tab4, text=\"Klasyfikator-Drzewo losowe\")\n",
    "        self.create_tab4_widgets()\n",
    "\n",
    "        self.tab5 = ttk.Frame(self.tabControl)\n",
    "        self.tabControl.add(self.tab5, text=\"Klasyfikator-Drzewo decyzyjne\")\n",
    "        self.create_tab5_widgets()\n",
    "\n",
    "        self.tab3 = ttk.Frame(self.tabControl)\n",
    "        self.tabControl.add(self.tab3, text=\"Grupowanie-KMeans\")\n",
    "        self.create_tab3_widgets()\n",
    "\n",
    "        self.tab6 = ttk.Frame(self.tabControl)\n",
    "        self.tabControl.add(self.tab6, text=\"Grupowanie-DBSCAN\")\n",
    "        self.create_tab6_widgets()\n",
    "\n",
    "        self.tab7 = ttk.Frame(self.tabControl)\n",
    "        self.tabControl.add(self.tab7, text=\"Grupowanie-Hierarchiczna\")\n",
    "        self.create_tab7_widgets()\n",
    "\n",
    "        self.script_text = tk.Text(self, height=20, width=100)\n",
    "        self.script_text.pack()\n",
    "\n",
    "        self.save_button = tk.Button(self, text=\"Zapisz\", command=self.save_script)\n",
    "        self.save_button.pack(side=tk.TOP)\n",
    "\n",
    "        self.run_button = tk.Button(self, text=\"Uruchom\", command=self.run_script)\n",
    "        self.run_button.pack(side=tk.TOP)\n",
    "\n",
    "        self.clear_button = tk.Button(self, text=\"Wyczyść\", command=self.clear_script)\n",
    "        self.clear_button.pack(side=tk.TOP)\n",
    "\n",
    "    def create_tab1_widgets(self):\n",
    "        self.script1_button = tk.Button(self.tab1)\n",
    "        self.script1_button[\"text\"] = \"Reguły asocjacyjne - wartości domyślne\"\n",
    "        self.script1_button[\"command\"] = self.add_text_ad\n",
    "        self.script1_button.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab1_var = tk.IntVar()\n",
    "        self.tab1_checkbox = tk.Checkbutton(self.tab1, text=\"Funkcje zaawansowane\", variable=self.tab1_var,\n",
    "                                            command=self.show_additional_functions)\n",
    "        self.tab1_checkbox.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab1_additional_label1 = tk.Label(self.tab1, text=\"Wsparcie\")\n",
    "        self.tab1_additional_label1.pack(side=tk.LEFT)\n",
    "        self.tab1_additional_label1.configure(state='disabled')\n",
    "\n",
    "        self.tab1_additional_field1 = tk.Entry(self.tab1)\n",
    "        self.tab1_additional_field1.pack(side=tk.LEFT)\n",
    "        self.tab1_additional_field1.bind(\"<Return>\", lambda event: self.add_additional_values_a())\n",
    "        self.tab1_additional_field1.configure(state='disabled')\n",
    "\n",
    "        self.tab1_additional_label2 = tk.Label(self.tab1, text=\"Zaufanie\")\n",
    "        self.tab1_additional_label2.pack(side=tk.LEFT)\n",
    "        self.tab1_additional_label2.configure(state='disabled')\n",
    "\n",
    "        self.tab1_additional_field2 = tk.Entry(self.tab1)\n",
    "        self.tab1_additional_field2.pack(side=tk.LEFT)\n",
    "        self.tab1_additional_field2.bind(\"<Return>\", lambda event: self.add_additional_values_a())\n",
    "        self.tab1_additional_field2.configure(state='disabled')\n",
    "\n",
    "    def create_tab2_widgets(self):\n",
    "        self.script2_button = tk.Button(self.tab2)\n",
    "        self.script2_button[\"text\"] = \"Train and Test - wartości domyślne\"\n",
    "        self.script2_button[\"command\"] = self.add_text_knn\n",
    "        self.script2_button.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab2_var = tk.IntVar()\n",
    "        self.tab2_checkbox = tk.Checkbutton(self.tab2, text=\"Funkcje zaawansowane\", variable=self.tab2_var,\n",
    "                                            command=self.show_additional_functions)\n",
    "        self.tab2_checkbox.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab2_additional_label1 = tk.Label(self.tab2, text=\"Rozmiar tablicy testowej\")\n",
    "        self.tab2_additional_label1.pack(side=tk.LEFT)\n",
    "        self.tab2_additional_label1.configure(state='disabled')\n",
    "\n",
    "        self.tab2_additional_field1 = tk.Entry(self.tab2)\n",
    "        self.tab2_additional_field1.pack(side=tk.LEFT)\n",
    "        self.tab2_additional_field1.bind(\"<Return>\", lambda event: self.add_additional_values_knn())\n",
    "        self.tab2_additional_field1.configure(state='disabled')\n",
    "\n",
    "        self.tab2_additional_label2 = tk.Label(self.tab2, text=\"Stan losowy\")\n",
    "        self.tab2_additional_label2.pack(side=tk.LEFT)\n",
    "        self.tab2_additional_label2.configure(state='disabled')\n",
    "\n",
    "        self.tab2_additional_field2 = tk.Entry(self.tab2)\n",
    "        self.tab2_additional_field2.pack(side=tk.LEFT)\n",
    "        self.tab2_additional_field2.bind(\"<Return>\", lambda event: self.add_additional_values_knn())\n",
    "        self.tab2_additional_field2.configure(state='disabled')\n",
    "\n",
    "        self.tab2_additional_label3 = tk.Label(self.tab2, text=\"Liczba sąsiadów\")\n",
    "        self.tab2_additional_label3.pack(side=tk.LEFT)\n",
    "        self.tab2_additional_label3.configure(state='disabled')\n",
    "\n",
    "        self.tab2_additional_field3 = tk.Entry(self.tab2)\n",
    "        self.tab2_additional_field3.pack(side=tk.LEFT)\n",
    "        self.tab2_additional_field3.bind(\"<Return>\", lambda event: self.add_additional_values_knn())\n",
    "        self.tab2_additional_field3.configure(state='disabled')\n",
    "\n",
    "        self.tab2_menu_label = tk.Label(self.tab2, text=\"Wybierz metrykę:\")\n",
    "        self.tab2_menu_label.pack(side=tk.LEFT)\n",
    "        self.tab2_menu_label.configure(state='disabled')\n",
    "\n",
    "        self.tab2_menu = ttk.Combobox(self.tab2, values=[\"euclidean\", \"manhattan\", \"minkowski\"])\n",
    "        self.tab2_menu.pack(side=tk.LEFT)\n",
    "        self.tab2_menu.bind(\"<Return>\", lambda event: self.add_additional_values_knn())\n",
    "        self.tab2_menu.configure(state='disabled')\n",
    "\n",
    "    def create_tab4_widgets(self):\n",
    "        self.script4_button = tk.Button(self.tab4)\n",
    "        self.script4_button[\"text\"] = \"Train and Test - wartości domyślne\"\n",
    "        self.script4_button[\"command\"] = self.add_text_dl\n",
    "        self.script4_button.pack(side=tk.TOP)\n",
    "        self.tab4_var = tk.IntVar()\n",
    "        self.tab4_checkbox = tk.Checkbutton(self.tab4, text=\"Funkcje zaawansowane\", variable=self.tab4_var,\n",
    "                                            command=self.show_additional_functions)\n",
    "        self.tab4_checkbox.pack(side=tk.TOP)\n",
    "        self.tab4_additional_label1 = tk.Label(self.tab4, text=\"Rozmiar tablicy testowej\")\n",
    "        self.tab4_additional_label1.pack(side=tk.LEFT)\n",
    "        self.tab4_additional_label1.configure(state='disabled')\n",
    "\n",
    "        self.tab4_additional_field1 = tk.Entry(self.tab4)\n",
    "        self.tab4_additional_field1.pack(side=tk.LEFT)\n",
    "        self.tab4_additional_field1.bind(\"<Return>\", lambda event: self.add_additional_values_dl())\n",
    "        self.tab4_additional_field1.configure(state='disabled')\n",
    "\n",
    "        self.tab4_additional_label2 = tk.Label(self.tab4, text=\"Stan losowy\")\n",
    "        self.tab4_additional_label2.pack(side=tk.LEFT)\n",
    "        self.tab4_additional_label2.configure(state='disabled')\n",
    "\n",
    "        self.tab4_additional_field2 = tk.Entry(self.tab4)\n",
    "        self.tab4_additional_field2.pack(side=tk.LEFT)\n",
    "        self.tab4_additional_field2.bind(\"<Return>\", lambda event: self.add_additional_values_dl())\n",
    "        self.tab4_additional_field2.configure(state='disabled')\n",
    "\n",
    "        self.tab4_additional_label3 = tk.Label(self.tab4, text=\"Liczba estymatorów\")\n",
    "        self.tab4_additional_label3.pack(side=tk.LEFT)\n",
    "        self.tab4_additional_label3.configure(state='disabled')\n",
    "\n",
    "        self.tab4_additional_field3 = tk.Entry(self.tab4)\n",
    "        self.tab4_additional_field3.pack(side=tk.LEFT)\n",
    "        self.tab4_additional_field3.bind(\"<Return>\", lambda event: self.add_additional_values_dl())\n",
    "        self.tab4_additional_field3.configure(state='disabled')\n",
    "\n",
    "        self.tab4_additional_label4 = tk.Label(self.tab4, text=\"Maksymalna głębokość\")\n",
    "        self.tab4_additional_label4.pack(side=tk.LEFT)\n",
    "        self.tab4_additional_label4.configure(state='disabled')\n",
    "\n",
    "        self.tab4_additional_field4 = tk.Entry(self.tab4)\n",
    "        self.tab4_additional_field4.pack(side=tk.LEFT)\n",
    "        self.tab4_additional_field4.bind(\"<Return>\", lambda event: self.add_additional_values_dl())\n",
    "        self.tab4_additional_field4.configure(state='disabled')\n",
    "\n",
    "    def create_tab5_widgets(self):\n",
    "        self.script5_button = tk.Button(self.tab5)\n",
    "        self.script5_button[\"text\"] = \"Train and Test - wartości domyślne\"\n",
    "        self.script5_button[\"command\"] = self.add_text_dd\n",
    "        self.script5_button.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab5_var = tk.IntVar()\n",
    "        self.tab5_checkbox = tk.Checkbutton(self.tab5, text=\"Funkcje zaawansowane\", variable=self.tab5_var,\n",
    "                                            command=self.show_additional_functions)\n",
    "        self.tab5_checkbox.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab5_additional_label1 = tk.Label(self.tab5, text=\"Rozmiar tablicy testowej\")\n",
    "        self.tab5_additional_label1.pack(side=tk.LEFT)\n",
    "        self.tab5_additional_label1.configure(state='disabled')\n",
    "\n",
    "        self.tab5_additional_field1 = tk.Entry(self.tab5)\n",
    "        self.tab5_additional_field1.pack(side=tk.LEFT)\n",
    "        self.tab5_additional_field1.bind(\"<Return>\", lambda event: self.add_additional_values_dd())\n",
    "        self.tab5_additional_field1.configure(state='disabled')\n",
    "\n",
    "        self.tab5_additional_label2 = tk.Label(self.tab5, text=\"Stan losowy\")\n",
    "        self.tab5_additional_label2.pack(side=tk.LEFT)\n",
    "        self.tab5_additional_label2.configure(state='disabled')\n",
    "\n",
    "        self.tab5_additional_field2 = tk.Entry(self.tab5)\n",
    "        self.tab5_additional_field2.pack(side=tk.LEFT)\n",
    "        self.tab5_additional_field2.bind(\"<Return>\", lambda event: self.add_additional_values_dd())\n",
    "        self.tab5_additional_field2.configure(state='disabled')\n",
    "\n",
    "        self.tab5_additional_label3 = tk.Label(self.tab5, text=\"Maksymalna głębokość\")\n",
    "        self.tab5_additional_label3.pack(side=tk.LEFT)\n",
    "        self.tab5_additional_label3.configure(state='disabled')\n",
    "\n",
    "        self.tab5_additional_field3 = tk.Entry(self.tab5)\n",
    "        self.tab5_additional_field3.pack(side=tk.LEFT)\n",
    "        self.tab5_additional_field3.bind(\"<Return>\", lambda event: self.add_additional_values_dd())\n",
    "        self.tab5_additional_field3.configure(state='disabled')\n",
    "\n",
    "    def create_tab3_widgets(self):\n",
    "        self.script3_button = tk.Button(self.tab3)\n",
    "        self.script3_button[\"text\"] = \"Grupowanie - wartości domyślne\"\n",
    "        self.script3_button[\"command\"] = self.add_text_gkm\n",
    "        self.script3_button.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab3_var = tk.IntVar()\n",
    "        self.tab3_checkbox = tk.Checkbutton(self.tab3, text=\"Funkcje zaawansowane\", variable=self.tab3_var,\n",
    "                                            command=self.show_additional_functions)\n",
    "        self.tab3_checkbox.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab3_additional_label1 = tk.Label(self.tab3, text=\"Liczba klastrów\")\n",
    "        self.tab3_additional_label1.pack(side=tk.LEFT)\n",
    "        self.tab3_additional_label1.configure(state='disabled')\n",
    "\n",
    "        self.tab3_additional_field1 = tk.Entry(self.tab3)\n",
    "        self.tab3_additional_field1.pack(side=tk.LEFT)\n",
    "        self.tab3_additional_field1.bind(\"<Return>\", lambda event: self.add_additional_values_gkm())\n",
    "        self.tab3_additional_field1.configure(state='disabled')\n",
    "\n",
    "        self.tab3_additional_label2 = tk.Label(self.tab3, text=\"Minimalna liczba iteracji\")\n",
    "        self.tab3_additional_label2.pack(side=tk.LEFT)\n",
    "        self.tab3_additional_label2.configure(state='disabled')\n",
    "\n",
    "        self.tab3_additional_field2 = tk.Entry(self.tab3)\n",
    "        self.tab3_additional_field2.pack(side=tk.LEFT)\n",
    "        self.tab3_additional_field2.bind(\"<Return>\", lambda event: self.add_additional_values_gkm())\n",
    "        self.tab3_additional_field2.configure(state='disabled')\n",
    "\n",
    "        self.tab3_additional_label3 = tk.Label(self.tab3, text=\"Maksymalna liczba iteracji\")\n",
    "        self.tab3_additional_label3.pack(side=tk.LEFT)\n",
    "        self.tab3_additional_label3.configure(state='disabled')\n",
    "\n",
    "        self.tab3_additional_field3 = tk.Entry(self.tab3)\n",
    "        self.tab3_additional_field3.pack(side=tk.LEFT)\n",
    "        self.tab3_additional_field3.bind(\"<Return>\", lambda event: self.add_additional_values_gkm())\n",
    "        self.tab3_additional_field3.configure(state='disabled')\n",
    "\n",
    "        self.tab3_additional_label4 = tk.Label(self.tab3, text=\"Stan losowy\")\n",
    "        self.tab3_additional_label4.pack(side=tk.LEFT)\n",
    "        self.tab3_additional_label4.configure(state='disabled')\n",
    "\n",
    "        self.tab3_additional_field4 = tk.Entry(self.tab3)\n",
    "        self.tab3_additional_field4.pack(side=tk.LEFT)\n",
    "        self.tab3_additional_field4.bind(\"<Return>\", lambda event: self.add_additional_values_gkm())\n",
    "        self.tab3_additional_field4.configure(state='disabled')\n",
    "\n",
    "    def create_tab6_widgets(self):\n",
    "        self.script6_button = tk.Button(self.tab6)\n",
    "        self.script6_button[\"text\"] = \"Grupowanie - wartości domyślne\"\n",
    "        self.script6_button[\"command\"] = self.add_text_gdb\n",
    "        self.script6_button.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab6_var = tk.IntVar()\n",
    "        self.tab6_checkbox = tk.Checkbutton(self.tab6, text=\"Funkcje zaawansowane\", variable=self.tab6_var,\n",
    "                                            command=self.show_additional_functions)\n",
    "        self.tab6_checkbox.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab6_additional_label1 = tk.Label(self.tab6, text=\"Wsparcie\")\n",
    "        self.tab6_additional_label1.pack(side=tk.LEFT)\n",
    "        self.tab6_additional_label1.configure(state='disabled')\n",
    "\n",
    "        self.tab6_additional_field1 = tk.Entry(self.tab6)\n",
    "        self.tab6_additional_field1.pack(side=tk.LEFT)\n",
    "        self.tab6_additional_field1.bind(\"<Return>\", lambda event: self.add_additional_values_gdb())\n",
    "        self.tab6_additional_field1.configure(state='disabled')\n",
    "\n",
    "        self.tab6_additional_label2 = tk.Label(self.tab6, text=\"Zaufanie\")\n",
    "        self.tab6_additional_label2.pack(side=tk.LEFT)\n",
    "        self.tab6_additional_label2.configure(state='disabled')\n",
    "\n",
    "        self.tab6_additional_field2 = tk.Entry(self.tab6)\n",
    "        self.tab6_additional_field2.pack(side=tk.LEFT)\n",
    "        self.tab6_additional_field2.bind(\"<Return>\", lambda event: self.add_additional_values_gdb())\n",
    "        self.tab6_additional_label2.configure(state='disabled')\n",
    "\n",
    "        self.tab6_menu_label = tk.Label(self.tab6, text=\"Wybierz metrykę:\")\n",
    "        self.tab6_menu_label.pack(side=tk.LEFT)\n",
    "        self.tab6_menu_label.configure(state='disabled')\n",
    "\n",
    "        self.tab6_menu = ttk.Combobox(self.tab6, values=[\"euclidean\", \"manhattan\", \"minkowski\"])\n",
    "        self.tab6_menu.bind(\"<Return>\", lambda event: self.add_additional_values_gdb())\n",
    "        self.tab6_menu.configure(state='disabled')\n",
    "        self.tab6_menu.pack(side=tk.LEFT)\n",
    "\n",
    "    def create_tab7_widgets(self):\n",
    "        self.script7_button = tk.Button(self.tab7)\n",
    "        self.script7_button[\"text\"] = \"Grupowanie - wartości domyślne\"\n",
    "        self.script7_button[\"command\"] = self.add_text_gh\n",
    "        self.script7_button.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab7_var = tk.IntVar()\n",
    "        self.tab7_checkbox = tk.Checkbutton(self.tab7, text=\"Funkcje zaawansowane\", variable=self.tab7_var,\n",
    "                                            command=self.show_additional_functions)\n",
    "        self.tab7_checkbox.pack(side=tk.TOP)\n",
    "\n",
    "        self.tab7_additional_label1 = tk.Label(self.tab7, text=\"Liczba klastrów\")\n",
    "        self.tab7_additional_label1.pack(side=tk.LEFT)\n",
    "        self.tab7_additional_label1.configure(state='disabled')\n",
    "\n",
    "        self.tab7_additional_field1 = tk.Entry(self.tab7)\n",
    "        self.tab7_additional_field1.pack(side=tk.LEFT)\n",
    "        self.tab7_additional_field1.bind(\"<Return>\", lambda event: self.add_additional_values_gh())\n",
    "        self.tab7_additional_field1.configure(state='disabled')\n",
    "\n",
    "        self.tab7_menu_label = tk.Label(self.tab7, text=\"Wybierz metrykę:\")\n",
    "        self.tab7_menu_label.pack(side=tk.LEFT)\n",
    "        self.tab7_menu_label.configure(state='disabled')\n",
    "\n",
    "        self.tab7_menu = ttk.Combobox(self.tab7, values=[\"euclidean\", \"manhattan\", \"minkowski\"])\n",
    "        self.tab7_menu.bind(\"<Return>\", lambda event: self.add_additional_values_gh())\n",
    "        self.tab7_menu.configure(state='disabled')\n",
    "        self.tab7_menu.pack(side=tk.LEFT)\n",
    "\n",
    "    def add_text_ad(self):\n",
    "            self.script_text.insert(tk.END, \"\"\"\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "st.header(\"Analiza reguł asocjacyjnych\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")  # Uploader plików\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "\n",
    "    min_support = st.slider('Minimalne wsparcie', min_value=0.0, max_value=1.0, value=0.1, step=0.01)  # Minimalne wsparcie\n",
    "    min_confidence = st.slider('Minimalne zaufanie', min_value=0.0, max_value=1.0, value=0.5, step=0.01)  # Minimalne zaufanie\n",
    "\n",
    "    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "    # Filtruj reguły według minimalnego zaufania\n",
    "    rules = rules[rules['confidence'] >= min_confidence]\n",
    "\n",
    "    st.write(\"Liczba reguł znalezionych: \", len(rules))\n",
    "\n",
    "    st.write(\"Najważniejsze reguły:\")\n",
    "    st.table(rules)\n",
    "\"\"\")\n",
    "\n",
    "    def add_text_knn(self):\n",
    "        self.script_text.insert(tk.END, \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "st.header(\"Analiza klasyfikatora KNN\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")   #Uploader plików\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file) #Odczytanie zbioru danych\n",
    "    st.write(df)   #Wypisanie data frame pliku\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny\", column_list[:-1],\n",
    "                                      default=[column_list[0], column_list[1]])  # Wybór kolumn dla cech\n",
    "    selected_labels = st.multiselect(\"Wybierz kolumny\", column_list[-1:], default=[column_list[-1]])  # Wybór kolumn dla etykiet\n",
    "\n",
    "    features = df[selected_columns]  # Wyodrębnienie części warunkowej danych\n",
    "    labels = df[selected_labels]  # Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "    ts = st.number_input('Rozmiar tablicy testowej', min_value=0.0, max_value=1.0, value=0.6, step=0.01) #Ustalenie tablicy treningowej\n",
    "    rs = st.number_input('Stan losowy', min_value=1, max_value=10000, value=1234, step=1) #Ustalenie ziarna generatora liczb pseudolosowych\n",
    "\n",
    "    datasets = train_test_split(features, labels, test_size=ts, random_state=rs)\n",
    "\n",
    "    features_train = datasets[0]\n",
    "    features_test = datasets[1]\n",
    "    labels_train = datasets[2]\n",
    "    labels_test = datasets[3]\n",
    "\n",
    "    nm = st.number_input('Liczba sąsiadów', min_value=1, max_value=10000, value=5, step=1)  #Liczba sąsiadów\n",
    "    myNoNeighbors = nm\n",
    "\n",
    "    choice = st.selectbox(  #Checkbox do wyboru metryki\n",
    "\n",
    "        'Wybierz jedną z dostępnych metryk',\n",
    "\n",
    "        ('euclidean', 'manhattan', 'minkowski'))\n",
    "    myMetric = choice\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=myNoNeighbors, metric=myMetric)  #Utworzenie obiektu przykładowego modelu klasyfikatora (k-NN)\n",
    "    model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "    labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted)  #Policzenie jakości klasyfikacji\n",
    "\n",
    "    st.write(\"Classification accuracy=\" ,accuracy)\n",
    "    st.write(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "    report = classification_report(labels_test, labels_predicted)\n",
    "    st.text(report)\n",
    "    st.write(\"====== Tablica pomyłek =========\")\n",
    "    conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "    st.write(conf_matrix)\n",
    "    \"\"\")\n",
    "\n",
    "    def add_text_dl(self):\n",
    "        self.script_text.insert(tk.END, \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "st.header(\"Analiza klasyfikatora drzewa losowego\")\n",
    "\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")   #Uploader plików\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file) #Odczytanie zbioru danych\n",
    "    st.write(df)   #Wypisanie data frame pliku\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny\", column_list[:-1],\n",
    "                                      default=[column_list[0], column_list[1]])  # Wybór kolumn dla cech\n",
    "    selected_labels = st.multiselect(\"Wybierz kolumny\", column_list[-1:], default=[column_list[-1]])  # Wybór kolumn dla etykiet\n",
    "\n",
    "    features = df[selected_columns]  # Wyodrębnienie części warunkowej danych\n",
    "    labels = df[selected_labels]  # Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "    ts = st.number_input('Rozmiar tablicy testowej', min_value=0.0, max_value=1.0, value=0.6, step=0.01) #Ustalenie tablicy treningowej\n",
    "    rs = st.number_input('Stan losowy', min_value=1, max_value=10000, value=1234, step=1) #Ustalenie ziarna generatora liczb pseudolosowych\n",
    "\n",
    "    datasets = train_test_split(features, labels, test_size=ts, random_state=rs)\n",
    "\n",
    "    features_train = datasets[0]\n",
    "    features_test = datasets[1]\n",
    "    labels_train = datasets[2]\n",
    "    labels_test = datasets[3]\n",
    "\n",
    "    n_estimators = st.number_input('Liczba estymatorów', min_value=1, max_value=10000, value=100, step=1)  #Liczba estymatorów w drzewie losowym\n",
    "    max_depth = st.number_input('Maksymalna głębokość', min_value=1, max_value=10000, value=5, step=1)  #Maksymalna głębokość drzewa\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)  #Utworzenie obiektu klasyfikatora drzewa losowego\n",
    "    model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "    labels_predicted = model.predict(features_test) #Generowanie decyzji dla części testowej\n",
    "\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted)  #Policzenie jakości klasyfikacji\n",
    "\n",
    "    st.write(\"Classification accuracy=\", accuracy)\n",
    "    st.write(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "    rf_report = classification_report(labels_test, labels_predicted, output_dict=True)\n",
    "    df_rf_report = pd.DataFrame(rf_report).transpose()\n",
    "    st.write(df_rf_report)\n",
    "    st.write(\"====== Tablica pomyłek =========\")\n",
    "    rf_conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "    st.write(rf_conf_matrix)\n",
    "        \"\"\")\n",
    "\n",
    "    def add_text_dd(self):\n",
    "        self.script_text.insert(tk.END, \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "st.header(\"Analiza klasyfikatora drzewa decyzyjnego\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")   #Uploader plików\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file) #Odczytanie zbioru danych\n",
    "    st.write(df)   #Wypisanie data frame pliku\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny\", column_list[:-1],\n",
    "                                      default=[column_list[0], column_list[1]])  # Wybór kolumn dla cech\n",
    "    selected_labels = st.multiselect(\"Wybierz kolumny\", column_list[-1:], default=[column_list[-1]])  # Wybór kolumn dla etykiet\n",
    "\n",
    "    features = df[selected_columns]  # Wyodrębnienie części warunkowej danych\n",
    "    labels = df[selected_labels]  # Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "    ts = st.number_input('Rozmiar tablicy testowej', min_value=0.0, max_value=1.0, value=0.6, step=0.01) #Ustalenie tablicy treningowej\n",
    "    rs = st.number_input('Stan losowy', min_value=1, max_value=10000, value=1234, step=1) #Ustalenie ziarna generatora liczb pseudolosowych\n",
    "\n",
    "    datasets = train_test_split(features, labels, test_size=ts, random_state=rs)\n",
    "\n",
    "    features_train = datasets[0]\n",
    "    features_test = datasets[1]\n",
    "    labels_train = datasets[2]\n",
    "    labels_test = datasets[3]\n",
    "\n",
    "    max_depth = st.number_input('Maksymalna głębokość', min_value=1, max_value=10000, value=5, step=1)  #Maksymalna głębokość drzewa\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth)  #Utworzenie obiektu klasyfikatora drzewa decyzyjnego\n",
    "    model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "    labels_predicted = model.predict(features_test) #Generowanie decyzji dla części testowej\n",
    "\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted)  #Policzenie jakości klasyfikacji\n",
    "\n",
    "    st.write(\"Classification accuracy=\", accuracy)\n",
    "    st.write(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "    report = classification_report(labels_test, labels_predicted, output_dict=True)\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    st.write(df_report)\n",
    "    st.write(\"====== Tablica pomyłek =========\")\n",
    "    conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "    st.write(conf_matrix)\n",
    "        \"\"\")\n",
    "\n",
    "    def add_text_gkm(self):\n",
    "        self.script_text.insert(tk.END, \"\"\"\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "st.header(\"Analiza grupowania KMeans\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")  # Uploader plików\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny do grupowania\", column_list, default=[column_list[0], column_list[3]])\n",
    "\n",
    "    if len(selected_columns) >= 2:\n",
    "        features = df[selected_columns]  # Wybór kolumn do grupowania\n",
    "        sFeatures = features\n",
    "        scaler = StandardScaler()\n",
    "        sFeatures = scaler.fit_transform(features)\n",
    "\n",
    "        nc = st.number_input('Liczba klastrów', min_value=0, max_value=1000, value=4,\n",
    "                                 step=1)  # Wybór liczby klastór\n",
    "        ni = st.number_input('Minimalna liczba iteracji', min_value=0, max_value=1000, value=10,\n",
    "                                 step=1)  # Wybór minimalnej liczby iteracji\n",
    "        mi = st.number_input('Maksymalna liczba iteracji', min_value=0, max_value=1000, value=1000,\n",
    "                                 step=1)  # Wybór maksymalnej liczby iteracji\n",
    "        rs = st.number_input('Stan losowy', min_value=0, max_value=10000, value=1234,\n",
    "                                 step=1)  # Ustalenie ziarna generatora liczb pseudolosowych\n",
    "\n",
    "        kmeans = KMeans(n_clusters=nc, init='k-means++', n_init=ni, max_iter=mi, random_state=rs)\n",
    "        kmeans.fit(sFeatures)  # Grupowanie\n",
    "\n",
    "        # Wizualizacja grupowania\n",
    "        centroidsKMeans = kmeans.cluster_centers_\n",
    "        centroidsKMeansX = centroidsKMeans[:, 0]\n",
    "        centroidsKMeansY = centroidsKMeans[:, 1]\n",
    "        clusters = kmeans.fit_predict(features)\n",
    "\n",
    "        x = sFeatures[:, 0]\n",
    "        y = sFeatures[:, 1]\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        scatter = ax.scatter(x, y, s=10, c=clusters, alpha=0.9)\n",
    "        centroids = ax.scatter(centroidsKMeansX, centroidsKMeansY, s=50, color=\"blue\", alpha=0.9)\n",
    "\n",
    "        # Dodanie etykiet wybranych kolumn\n",
    "        ax.set_xlabel(selected_columns[0])\n",
    "        ax.set_ylabel(selected_columns[1])\n",
    "\n",
    "        ax.legend([scatter, centroids], ['Data Points', 'Centroids'])\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.write(\"Przyporządkowanie poszczególnych obiektów do skupień:\")\n",
    "        data = {\"Skupienie\": [], \"Obiekty\": []}\n",
    "        for i in range(nc):\n",
    "            cluster_indices = [index for index, cluster in enumerate(clusters) if cluster == i]\n",
    "            objects = \", \".join([str(index + 1) for index in cluster_indices])\n",
    "            data[\"Skupienie\"].append(i)\n",
    "            data[\"Obiekty\"].append(objects)\n",
    "        cluster_data = pd.DataFrame(data)\n",
    "        st.table(cluster_data)\n",
    "    else:\n",
    "        st.write(\"Wybierz co najmniej dwie kolumny do grupowania.\")\n",
    "        \"\"\")\n",
    "\n",
    "    def add_text_gdb(self):\n",
    "        self.script_text.insert(tk.END, \"\"\"\n",
    "from sklearn.cluster import DBSCAN\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "st.header(\"Analiza grupowania DBSCAN\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\", key='2')  # Uploader plików\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny do grupowania\", column_list,default=[column_list[0], column_list[3]])\n",
    "\n",
    "    if len(selected_columns) >= 2:\n",
    "        features = df[selected_columns]  # Wybór kolumn do grupowania\n",
    "        e = st.number_input('Maksymalna odległość między obserwacjami, które należy uznać za sąsiadujące.', min_value=0,\n",
    "                                max_value=1000, value=3, step=1)\n",
    "        ms = st.number_input('Minimalna liczba próbek', min_value=0, max_value=1000, value=5, step=1)\n",
    "        met = st.selectbox('Wybierz jedną z dostępnych metryk', ('euclidean', 'manhattan', 'minkowski'))\n",
    "\n",
    "        db = DBSCAN(eps=e, min_samples=ms, metric=met)\n",
    "        db.fit(features)\n",
    "\n",
    "        clusters = db.fit_predict(features)\n",
    "\n",
    "        x = np.ravel(features.iloc[:, [0]])\n",
    "        y = np.ravel(features.iloc[:, [1]])\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        scatter = ax.scatter(x, y, s=10, c=clusters, alpha=0.9)\n",
    "\n",
    "        # Dodanie etykiet wybranych kolumn\n",
    "        ax.set_xlabel(selected_columns[0])\n",
    "        ax.set_ylabel(selected_columns[1])\n",
    "\n",
    "        ax.legend([scatter], ['Data Points'])\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.write(\"Przyporządkowanie poszczególnych obiektów do skupień:\")\n",
    "        data = {\"Skupienie\": [], \"Obiekty\": []}\n",
    "        for i in range(len(np.unique(clusters))):\n",
    "            cluster_indices = [index for index, cluster in enumerate(clusters) if cluster == i]\n",
    "            objects = \", \".join([str(index + 1) for index in cluster_indices])\n",
    "            data[\"Skupienie\"].append(i)\n",
    "            data[\"Obiekty\"].append(objects)\n",
    "        cluster_data = pd.DataFrame(data)\n",
    "        st.table(cluster_data)\n",
    "    else:\n",
    "        st.write(\"Wybierz co najmniej dwie kolumny do grupowania.\")\n",
    "        \"\"\")\n",
    "\n",
    "    def add_text_gh(self):\n",
    "        self.script_text.insert(tk.END, \"\"\"\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "st.header(\"Analiza grupowania hierarchicznego\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\", key='3')  # Uploader plików\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny do grupowania\", column_list, default=[column_list[0], column_list[3]], key='4')\n",
    "\n",
    "    if len(selected_columns) >= 2:\n",
    "        features = df[selected_columns]  # Wybór kolumn do grupowania\n",
    "\n",
    "        nc = st.number_input('Liczba klastrów', min_value=0, max_value=1000, value=4,\n",
    "                             step=1, key='num_clusters')  # Wybór liczby klastrów\n",
    "        met = st.selectbox('Wybierz jedną z dostępnych metryk', ('euclidean', 'manhattan', 'minkowski'))\n",
    "\n",
    "        ac = AgglomerativeClustering(n_clusters=nc, affinity=met, linkage=('average'))\n",
    "        ac.fit(features)\n",
    "\n",
    "        clusters = ac.fit_predict(features)\n",
    "\n",
    "        x = np.ravel(features.iloc[:, [0]])\n",
    "        y = np.ravel(features.iloc[:, [1]])\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        scatter = ax.scatter(x, y, s=10, c=clusters, alpha=0.9)\n",
    "\n",
    "        # Dodanie etykiet wybranych kolumn\n",
    "        ax.set_xlabel(selected_columns[0])\n",
    "        ax.set_ylabel(selected_columns[1])\n",
    "\n",
    "        ax.legend([scatter], ['Data Points'])\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.write(\"Przyporządkowanie poszczególnych obiektów do skupień:\")\n",
    "        data = {\"Skupienie\": [], \"Obiekty\": []}\n",
    "        for i in range(nc):\n",
    "            cluster_indices = [index for index, cluster in enumerate(clusters) if cluster == i]\n",
    "            objects = \", \".join([str(index + 1) for index in cluster_indices])\n",
    "            data[\"Skupienie\"].append(i)\n",
    "            data[\"Obiekty\"].append(objects)\n",
    "        cluster_data = pd.DataFrame(data)\n",
    "        st.table(cluster_data)\n",
    "    else:\n",
    "        st.write(\"Wybierz co najmniej dwie kolumny do grupowania.\")\n",
    "        \"\"\")\n",
    "\n",
    "    def show_additional_functions(self):\n",
    "\n",
    "        if self.tab1_var.get():\n",
    "            self.tab1_additional_label1.configure(state='normal')\n",
    "            self.tab1_additional_label2.configure(state='normal')\n",
    "            self.tab1_additional_field1.configure(state='normal')\n",
    "            self.tab1_additional_field2.configure(state='normal')\n",
    "        else:\n",
    "            self.tab1_additional_label1.configure(state='disabled')\n",
    "            self.tab1_additional_label2.configure(state='disabled')\n",
    "            self.tab1_additional_field1.configure(state='disabled')\n",
    "            self.tab1_additional_field2.configure(state='disabled')\n",
    "\n",
    "        if self.tab2_var.get():\n",
    "            self.tab2_additional_label1.configure(state='normal')\n",
    "            self.tab2_additional_label2.configure(state='normal')\n",
    "            self.tab2_additional_label3.configure(state='normal')\n",
    "            self.tab2_additional_field1.configure(state='normal')\n",
    "            self.tab2_additional_field2.configure(state='normal')\n",
    "            self.tab2_additional_field3.configure(state='normal')\n",
    "            self.tab2_menu_label.configure(state='normal')\n",
    "            self.tab2_menu.configure(state='normal')\n",
    "        else:\n",
    "            self.tab2_additional_label1.configure(state='disabled')\n",
    "            self.tab2_additional_label2.configure(state='disabled')\n",
    "            self.tab2_additional_label3.configure(state='disabled')\n",
    "            self.tab2_additional_field1.configure(state='disabled')\n",
    "            self.tab2_additional_field2.configure(state='disabled')\n",
    "            self.tab2_additional_field3.configure(state='disabled')\n",
    "            self.tab2_menu_label.configure(state='disabled')\n",
    "            self.tab2_menu.configure(state='disabled')\n",
    "\n",
    "        if self.tab4_var.get():\n",
    "            self.tab4_additional_label1.configure(state='normal')\n",
    "            self.tab4_additional_label2.configure(state='normal')\n",
    "            self.tab4_additional_label3.configure(state='normal')\n",
    "            self.tab4_additional_label4.configure(state='normal')\n",
    "            self.tab4_additional_field1.configure(state='normal')\n",
    "            self.tab4_additional_field2.configure(state='normal')\n",
    "            self.tab4_additional_field3.configure(state='normal')\n",
    "            self.tab4_additional_field4.configure(state='normal')\n",
    "        else:\n",
    "            self.tab4_additional_label1.configure(state='disabled')\n",
    "            self.tab4_additional_label2.configure(state='disabled')\n",
    "            self.tab4_additional_label3.configure(state='disabled')\n",
    "            self.tab4_additional_label4.configure(state='disabled')\n",
    "            self.tab4_additional_field1.configure(state='disabled')\n",
    "            self.tab4_additional_field2.configure(state='disabled')\n",
    "            self.tab4_additional_field3.configure(state='disabled')\n",
    "            self.tab4_additional_field4.configure(state='disabled')\n",
    "\n",
    "        if self.tab5_var.get():\n",
    "            self.tab5_additional_label1.configure(state='normal')\n",
    "            self.tab5_additional_label2.configure(state='normal')\n",
    "            self.tab5_additional_label3.configure(state='normal')\n",
    "            self.tab5_additional_field1.configure(state='normal')\n",
    "            self.tab5_additional_field2.configure(state='normal')\n",
    "            self.tab5_additional_field3.configure(state='normal')\n",
    "        else:\n",
    "            self.tab5_additional_label1.configure(state='disabled')\n",
    "            self.tab5_additional_label2.configure(state='disabled')\n",
    "            self.tab5_additional_label3.configure(state='disabled')\n",
    "            self.tab5_additional_field1.configure(state='disabled')\n",
    "            self.tab5_additional_field2.configure(state='disabled')\n",
    "            self.tab5_additional_field3.configure(state='disabled')\n",
    "\n",
    "        if self.tab3_var.get():\n",
    "            self.tab3_additional_label1.configure(state='normal')\n",
    "            self.tab3_additional_label2.configure(state='normal')\n",
    "            self.tab3_additional_label3.configure(state='normal')\n",
    "            self.tab3_additional_label4.configure(state='normal')\n",
    "            self.tab3_additional_field1.configure(state='normal')\n",
    "            self.tab3_additional_field2.configure(state='normal')\n",
    "            self.tab3_additional_field3.configure(state='normal')\n",
    "            self.tab3_additional_field4.configure(state='normal')\n",
    "        else:\n",
    "            self.tab3_additional_label1.configure(state='disabled')\n",
    "            self.tab3_additional_label2.configure(state='disabled')\n",
    "            self.tab3_additional_label3.configure(state='disabled')\n",
    "            self.tab3_additional_label4.configure(state='disabled')\n",
    "            self.tab3_additional_field1.configure(state='disabled')\n",
    "            self.tab3_additional_field2.configure(state='disabled')\n",
    "            self.tab3_additional_field3.configure(state='disabled')\n",
    "            self.tab3_additional_field4.configure(state='disabled')\n",
    "\n",
    "        if self.tab6_var.get():\n",
    "            self.tab6_additional_label1.configure(state='normal')\n",
    "            self.tab6_additional_label2.configure(state='normal')\n",
    "            self.tab6_additional_field1.configure(state='normal')\n",
    "            self.tab6_additional_field2.configure(state='normal')\n",
    "            self.tab6_menu_label.configure(state='normal')\n",
    "            self.tab6_menu.configure(state='normal')\n",
    "        else:\n",
    "            self.tab6_additional_label1.configure(state='disabled')\n",
    "            self.tab6_additional_field1.configure(state='disabled')\n",
    "            self.tab6_additional_label2.configure(state='disabled')\n",
    "            self.tab6_additional_field2.configure(state='disabled')\n",
    "            self.tab6_menu_label.configure(state='disabled')\n",
    "            self.tab6_menu.configure(state='disabled')\n",
    "\n",
    "        if self.tab7_var.get():\n",
    "            self.tab7_additional_label1.configure(state='normal')\n",
    "            self.tab7_additional_field1.configure(state='normal')\n",
    "            self.tab7_menu_label.configure(state='normal')\n",
    "            self.tab7_menu.configure(state='normal')\n",
    "\n",
    "        else:\n",
    "            self.tab7_additional_label1.configure(state='disabled')\n",
    "            self.tab7_additional_field1.configure(state='disabled')\n",
    "            self.tab7_menu_label.configure(state='disabled')\n",
    "            self.tab7_menu.configure(state='disabled')\n",
    "\n",
    "        self.script_text.delete(\"1.0\", tk.END)\n",
    "\n",
    "    def add_additional_values_a(self, event=None):\n",
    "        support = self.tab1_additional_field1.get()\n",
    "        if not support:  # Jeśli wartość support nie została podana\n",
    "            support = \"0.15\"  # Przypisz wartość domyślną\n",
    "\n",
    "        confidence = self.tab1_additional_field2.get()\n",
    "        if not confidence:  # Jeśli wartość confidence nie została podana\n",
    "            confidence = \"0.5\"  # Przypisz wartość domyślną\n",
    "\n",
    "        additional_text = \"\"\"\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "st.header(\"Analiza reguł asocjacyjnych\")\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")  # Uploader plików\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "    \"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        additional_values = f\"min_support = {support}\\n    min_confidence = {confidence}\\n\"\n",
    "\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "        additional_text = \"\"\"\n",
    "    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "    # Filtruj reguły według minimalnego zaufania\n",
    "    rules = rules[rules['confidence'] >= min_confidence]\n",
    "\n",
    "    st.write(\"Liczba reguł znalezionych: \", len(rules))\n",
    "\n",
    "    st.write(\"Najważniejsze reguły:\")\n",
    "    st.table(rules)        \"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "        self.tab1_additional_field1.delete(0, tk.END)\n",
    "        self.tab1_additional_field2.delete(0, tk.END)\n",
    "\n",
    "    def add_additional_values_knn(self, event=None):\n",
    "        ts = self.tab2_additional_field1.get()\n",
    "        if not ts:\n",
    "            ts = \"0.6\"\n",
    "        rs = self.tab2_additional_field2.get()\n",
    "        if not rs:\n",
    "            rs = \"1234\"\n",
    "        nm = self.tab2_additional_field3.get()\n",
    "        if not nm:\n",
    "            nm = \"5\"\n",
    "        choice = self.tab2_menu.get()\n",
    "        if not choice:\n",
    "            choice = \"euclidean\"\n",
    "\n",
    "        additional_text = \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "st.header(\"Analiza klasyfikatora KNN\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")   #Uploader plików\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file) #Odczytanie zbioru danych\n",
    "    st.write(df)   #Wypisanie data frame pliku\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybór kolumn dla cech\", column_list[:-1], default=[column_list[0], column_list[1]])  # Wybór kolumn dla cech\n",
    "    selected_labels = st.multiselect(\"Wybór kolumn dla etykiet\", column_list[-1:], default=[column_list[-1]])  # Wybór kolumn dla etykiet\n",
    "    features = df[selected_columns]  # Wyodrębnienie części warunkowej danych\n",
    "    labels = df[selected_labels]  # Wyodrębnienie kolumny decyzyjnej\n",
    "\"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        additional_values = f\"    ts = {ts}\\n    rs = {rs}\\n\"\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "        additional_text = \"\"\"\n",
    "    datasets = train_test_split(features, labels, test_size=ts, random_state=rs)\n",
    "\n",
    "    features_train = datasets[0]\n",
    "    features_test = datasets[1]\n",
    "    labels_train = datasets[2]\n",
    "    labels_test = datasets[3]\n",
    "\"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        additional_values = f\"    nm = {nm}\\n\"\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "\n",
    "        additional_values = f\"    myMetric = '{choice}'\\n\"\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "\n",
    "        additional_text = \"\"\"\n",
    "    #Utworzenie obiektu przykładowego modelu klasyfikatora (k-NN)\n",
    "    model = KNeighborsClassifier(n_neighbors=nm, metric=myMetric)  \n",
    "    #Uczenie klasyfikatora na części treningowej\n",
    "    model.fit(features_train, np.ravel(labels_train)) \n",
    "\n",
    "    labels_predicted = model.predict(features_test) #Generowania decyzji dla części testowej\n",
    "\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted)  #Policzenie jakości klasyfikacji\n",
    "\n",
    "    st.write(\"Classification accuracy=\" ,accuracy)\n",
    "    st.write(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "    knn_report = classification_report(labels_test, labels_predicted, output_dict=True)\n",
    "    report = pd.DataFrame(knn_report).transpose()\n",
    "    st.text(report)\n",
    "    st.write(\"====== Tablica pomyłek =========\")\n",
    "    conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "    st.write(conf_matrix)\n",
    "                    \"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        self.tab2_additional_field1.delete(0, tk.END)\n",
    "        self.tab2_additional_field2.delete(0, tk.END)\n",
    "\n",
    "    def add_additional_values_dl(self, event=None):\n",
    "        ts = self.tab4_additional_field1.get()\n",
    "        if not ts:\n",
    "            ts= \"0.5\"\n",
    "        rs = self.tab4_additional_field2.get()\n",
    "        if not rs:\n",
    "            rs= \"1234\"\n",
    "        ne = self.tab4_additional_field3.get()\n",
    "        if not ne:\n",
    "            ne= \"100\"\n",
    "        md = self.tab4_additional_field4.get()\n",
    "        if not md:\n",
    "            md= \"5\"\n",
    "        additional_text = \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "st.header(\"Analiza klasyfikatora drzewa losowego\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")  # Uploader plików\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybór kolumn dla cech\", column_list[:-1], default=[column_list[0], column_list[1]])  # Wybór kolumn dla cech\n",
    "    selected_labels = st.multiselect(\"Wybór kolumn dla etykiet\", column_list[-1:], default=[column_list[-1]])  # Wybór kolumn dla etykiet\n",
    "\n",
    "    features = df[selected_columns]  # Wyodrębnienie części warunkowej danych\n",
    "    labels = df[selected_labels]  # Wyodrębnienie kolumny decyzyjnej\n",
    "\n",
    "\"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        additional_values = f\"    ts = {ts}\\n    rs = {rs}\\n\"\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "        additional_text = \"\"\"\n",
    "    datasets = train_test_split(features, labels, test_size=ts, random_state=rs)\n",
    "\n",
    "    features_train = datasets[0]\n",
    "    features_test = datasets[1]\n",
    "    labels_train = datasets[2]\n",
    "    labels_test = datasets[3]\n",
    "\"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        additional_values = f\"    n_estimators = {ne}\\n    max_depth = {md}\\n\"\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "\n",
    "        additional_text = \"\"\"\n",
    "    #Utworzenie obiektu klasyfikatora drzewa losowego\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    #Uczenie klasyfikatora na części treningowej  \n",
    "    model.fit(features_train, np.ravel(labels_train)) \n",
    "\n",
    "    labels_predicted = model.predict(features_test) #Generowanie decyzji dla części testowej\n",
    "\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted)  #Policzenie jakości klasyfikacji\n",
    "\n",
    "    st.write(\"Classification accuracy=\", accuracy)\n",
    "    st.write(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "    rf_report = classification_report(labels_test, labels_predicted, output_dict=True)\n",
    "    df_rf_report = pd.DataFrame(rf_report).transpose()\n",
    "    st.write(df_rf_report)\n",
    "    st.write(\"====== Tablica pomyłek =========\")\n",
    "    rf_conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "    st.write(rf_conf_matrix)\n",
    "        \"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "    def add_additional_values_dd(self, event=None):\n",
    "            ts = self.tab5_additional_field1.get()\n",
    "            if not ts:\n",
    "                ts = \"0.6\"\n",
    "            rs = self.tab5_additional_field2.get()\n",
    "            if not rs:\n",
    "                rs = \"1234\"\n",
    "            md = self.tab5_additional_field3.get()\n",
    "            if not md:\n",
    "                md = \"5\"\n",
    "            additional_text = \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "st.header(\"Analiza klasyfikatora drzewa decyzyjnego\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")   #Uploader plików\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file) #Odczytanie zbioru danych\n",
    "    st.write(df)   #Wypisanie data frame pliku\n",
    "    column_list = list(df.columns)\n",
    "    # Wybór kolumn dla cech\n",
    "    selected_columns = st.multiselect(\"Wybór kolumn dla cech\", column_list[:-1],\n",
    "                                      default=[column_list[0], column_list[1]])  \n",
    "    # Wybór kolumn dla etykiet\n",
    "    selected_labels = st.multiselect(\"Wybór kolumn dla etykiet\", column_list[-1:], default=[column_list[-1]])  \n",
    "\n",
    "    features = df[selected_columns]  # Wyodrębnienie części warunkowej danych\n",
    "    labels = df[selected_labels]  # Wyodrębnienie kolumny decyzyjnej\n",
    "\"\"\"\n",
    "            self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "            additional_values = f\"    ts = {ts}\\n    rs = {rs}\\n\"\n",
    "            self.script_text.insert(tk.END, additional_values)\n",
    "            additional_text = \"\"\"\n",
    "    datasets = train_test_split(features, labels, test_size=ts, random_state=rs)\n",
    "\n",
    "    features_train = datasets[0]\n",
    "    features_test = datasets[1]\n",
    "    labels_train = datasets[2]\n",
    "    labels_test = datasets[3]\n",
    "\"\"\"\n",
    "            self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "            additional_values = f\"    max_depth = {md}\\n    \"\n",
    "            self.script_text.insert(tk.END, additional_values)\n",
    "\n",
    "            additional_text = \"\"\"\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth)  #Utworzenie obiektu klasyfikatora drzewa decyzyjnego\n",
    "    model.fit(features_train, np.ravel(labels_train)) #Uczenie klasyfikatora na części treningowej\n",
    "\n",
    "    labels_predicted = model.predict(features_test) #Generowanie decyzji dla części testowej\n",
    "\n",
    "    accuracy = metrics.accuracy_score(labels_test, labels_predicted)  #Policzenie jakości klasyfikacji\n",
    "\n",
    "    st.write(\"Classification accuracy=\", accuracy)\n",
    "    st.write(\"========= PEŁNE WYNIKI KLASYFIKACJI ================\")\n",
    "    report = classification_report(labels_test, labels_predicted, output_dict=True)\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    st.write(df_report)\n",
    "    st.write(\"====== Tablica pomyłek =========\")\n",
    "    conf_matrix = confusion_matrix(labels_test, labels_predicted)\n",
    "    st.write(conf_matrix)\n",
    "            \"\"\"\n",
    "            self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "    def add_additional_values_gkm(self, event=None):\n",
    "        nc = self.tab3_additional_field1.get()\n",
    "        if not nc:\n",
    "            nc = \"4\"\n",
    "        ni = self.tab3_additional_field2.get()\n",
    "        if not ni:\n",
    "            ni = \"10\"\n",
    "        mi = self.tab3_additional_field3.get()\n",
    "        if not mi:\n",
    "            mi = \"1000\"\n",
    "        rs = self.tab3_additional_field4.get()\n",
    "        if not rs:\n",
    "            rs = \"1234\"\n",
    "        additional_text = \"\"\"\n",
    "from sklearn.cluster import KMeans\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "st.header(\"Analiza grupowania KMeans\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")  # Uploader plików\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny do grupowania\", column_list, \n",
    "    default=[column_list[0], column_list[3]])\n",
    "    if len(selected_columns) >= 2:\n",
    "        features = df[selected_columns]  # Wybór kolumn do grupowania\n",
    "        sFeatures = features\n",
    "        scaler = StandardScaler()\n",
    "        sFeatures = scaler.fit_transform(features)\n",
    "\"\"\"\n",
    "\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "        additional_values = f\"        nc = {nc}\\n        ni = {ni}\\n        mi = {mi}\\n        rs = {rs}\\n\"\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "\n",
    "        additional_text = \"\"\"\n",
    "        kmeans = KMeans(n_clusters=nc, init='k-means++', n_init=ni, max_iter=mi, random_state=rs)\n",
    "        kmeans.fit(sFeatures)  # Grupowanie\n",
    "\n",
    "        # Wizualizacja grupowania\n",
    "        centroidsKMeans = kmeans.cluster_centers_\n",
    "        centroidsKMeansX = centroidsKMeans[:, 0]\n",
    "        centroidsKMeansY = centroidsKMeans[:, 1]\n",
    "        clusters = kmeans.fit_predict(features)\n",
    "\n",
    "        x = sFeatures[:, 0]\n",
    "        y = sFeatures[:, 1]\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        scatter = ax.scatter(x, y, s=10, c=clusters, alpha=0.9)\n",
    "        centroids = ax.scatter(centroidsKMeansX, centroidsKMeansY, s=50, color=\"blue\", alpha=0.9)\n",
    "\n",
    "        # Dodanie etykiet wybranych kolumn\n",
    "        ax.set_xlabel(selected_columns[0])\n",
    "        ax.set_ylabel(selected_columns[1])\n",
    "\n",
    "        ax.legend([scatter, centroids], ['Data Points', 'Centroids'])\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.write(\"Przyporządkowanie poszczególnych obiektów do skupień:\")\n",
    "        data = {\"Skupienie\": [], \"Obiekty\": []}\n",
    "        for i in range(nc):\n",
    "            cluster_indices = [index for index, cluster in enumerate(clusters) if cluster == i]\n",
    "            objects = \", \".join([str(index + 1) for index in cluster_indices])\n",
    "            data[\"Skupienie\"].append(i)\n",
    "            data[\"Obiekty\"].append(objects)\n",
    "        cluster_data = pd.DataFrame(data)\n",
    "        st.table(cluster_data)\n",
    "    else:\n",
    "        st.write(\"Wybierz co najmniej dwie kolumny do grupowania.\")\n",
    "        \"\"\"\n",
    "\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        self.tab3_additional_field1.delete(0, tk.END)\n",
    "        self.tab3_additional_field2.delete(0, tk.END)\n",
    "\n",
    "    def add_additional_values_gdb(self, event=None):\n",
    "        e = self.tab6_additional_field1.get()\n",
    "        if not e:\n",
    "            e = \"3\"\n",
    "        ms = self.tab6_additional_field2.get()\n",
    "        if not ms:\n",
    "            ms = \"5\"\n",
    "        met = self.menu.get()\n",
    "        if not met:\n",
    "            met = \"3\"\n",
    "        additional_text = \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "st.header(\"Analiza grupowania DBSCAN)\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\")  # Uploader plików\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny do grupowania\", column_list, \n",
    "    default=[column_list[0], column_list[3]])\n",
    "    if len(selected_columns) >= 2:\n",
    "        features = df[selected_columns]  # Wybór kolumn do grupowania\n",
    "\"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        additional_values = f\"        e = {e}\\n        ms = {ms}\\n\"\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "\n",
    "        additional_values = f\"        met = '{met}'\\n\"\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "\n",
    "        additional_text = \"\"\"\n",
    "        db = DBSCAN(eps=e, min_samples=ms, metric=met)\n",
    "        db.fit(features)\n",
    "\n",
    "        clusters = db.fit_predict(features)\n",
    "\n",
    "        x = np.ravel(features.iloc[:, [0]])\n",
    "        y = np.ravel(features.iloc[:, [1]])\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        scatter = ax.scatter(x, y, s=10, c=clusters, alpha=0.9)\n",
    "\n",
    "        # Dodanie etykiet wybranych kolumn\n",
    "        ax.set_xlabel(selected_columns[0])\n",
    "        ax.set_ylabel(selected_columns[1])\n",
    "\n",
    "        ax.legend([scatter], ['Data Points'])\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.write(\"Przyporządkowanie poszczególnych obiektów do skupień:\")\n",
    "        data = {\"Skupienie\": [], \"Obiekty\": []}\n",
    "        for i in range(len(np.unique(clusters))):\n",
    "            cluster_indices = [index for index, cluster in enumerate(clusters) if cluster == i]\n",
    "            objects = \", \".join([str(index + 1) for index in cluster_indices])\n",
    "            data[\"Skupienie\"].append(i)\n",
    "            data[\"Obiekty\"].append(objects)\n",
    "        cluster_data = pd.DataFrame(data)\n",
    "        st.table(cluster_data)\n",
    "    else:\n",
    "        st.write(\"Wybierz co najmniej dwie kolumny do grupowania.\")\n",
    "\"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "    def add_additional_values_gh(self, event=None):\n",
    "        nc = self.tab7_additional_field1.get()\n",
    "        met = self.menu.get()\n",
    "\n",
    "        additional_text = \"\"\"\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "st.header(\"Analiza grupowania hierarchicznego\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Wybierz plik\", key='3')  # Uploader plików\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)  # Odczytanie zbioru danych\n",
    "    st.write(df)  # Wypisanie data frame pliku\n",
    "\n",
    "    column_list = list(df.columns)\n",
    "    selected_columns = st.multiselect(\"Wybierz kolumny do grupowania\", column_list, key='4')\n",
    "    if len(selected_columns) >= 2:\n",
    "        features = df[selected_columns]  # Wybór kolumn do grupowania\n",
    "\"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "\n",
    "        additional_values = f\"        nc = {nc}\\n        met = '{met}'\\n\"\n",
    "\n",
    "        self.script_text.insert(tk.END, additional_values)\n",
    "\n",
    "        additional_text = \"\"\"\n",
    "        ac = AgglomerativeClustering(n_clusters=nc, affinity=met,linkage=('average'))\n",
    "        ac.fit(features)\n",
    "\n",
    "        clusters = ac.fit_predict(features)\n",
    "\n",
    "        x = np.ravel(features.iloc[:, [0]])\n",
    "        y = np.ravel(features.iloc[:, [1]])\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        scatter = ax.scatter(x, y, s=10, c=clusters, alpha=0.9)\n",
    "\n",
    "        # Dodanie etykiet wybranych kolumn\n",
    "        ax.set_xlabel(selected_columns[0])\n",
    "        ax.set_ylabel(selected_columns[1])\n",
    "\n",
    "        ax.legend([scatter], ['Data Points'])\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.write(\"Przyporządkowanie poszczególnych obiektów do skupień:\")\n",
    "        data = {\"Skupienie\": [], \"Obiekty\": []}\n",
    "        for i in range(nc):\n",
    "            cluster_indices = [index for index, cluster in enumerate(clusters) if cluster == i]\n",
    "            objects = \", \".join([str(index + 1) for index in cluster_indices])\n",
    "            data[\"Skupienie\"].append(i)\n",
    "            data[\"Obiekty\"].append(objects)\n",
    "        cluster_data = pd.DataFrame(data)\n",
    "        st.table(cluster_data)\n",
    "    else:\n",
    "        st.write(\"Wybierz co najmniej dwie kolumny do grupowania.\")        \n",
    "\"\"\"\n",
    "        self.script_text.insert(tk.END, additional_text)\n",
    "    def save_script(self):\n",
    "        script = self.script_text.get(\"1.0\", tk.END)\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".py\", initialfile=\"skrypt\")\n",
    "        if filename:\n",
    "            with open(filename, \"w\", encoding='utf-8') as f:\n",
    "                f.write(script)\n",
    "\n",
    "    def clear_script(self):\n",
    "        self.script_text.delete(\"1.0\", tk.END)\n",
    "\n",
    "    def run_script(self):\n",
    "        script = self.script_text.get(\"1.0\", tk.END)\n",
    "        filename = \"temp_script.py\"\n",
    "        with open(filename, \"w\", encoding='utf-8') as f:\n",
    "            f.write(script)\n",
    "        subprocess.Popen([\"streamlit\", \"run\", filename])\n",
    "        self.clear_script()\n",
    " \n",
    "root = tk.Tk()\n",
    "app = Application(master=root)\n",
    "app.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
